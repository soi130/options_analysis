{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This is a personal project to grasp some concept of SET50 Options pricing.  The historical Options price was mannually collected by myself on a daily basis with a Google Sheet during those trading days. \n",
    "\n",
    "Here is how it lool like on a speadsheet:\n",
    "\n",
    "![options_sheet](options_sheet.png)\n",
    "\n",
    "I have been trading Options for several years and still wanting to better understand the pricing of the Options, so, as a data analyst, I think I will use some of the DA tools to help me grasp a better picture of Options Pricing.\n",
    "\n",
    "----------------\n",
    "\n",
    "Options is a derivative origanally aim to be used as an insurance for an underlying asset volatility during a certain period of time. And just like any insurances, the buyer need to pay the insurance premium to get insured, but, a million dollar question is, \"How much\" you should pay or sell for an option at a certain time.\n",
    "\n",
    "Since Options premium depends a lot on: \n",
    "- underlying's volatility and \n",
    "- time to expiration \n",
    "This notebook thus aim to map Options premium to both of the factors.\n",
    "\n",
    "For anyone who want to learn more about Options, here's a [link](https://www.investopedia.com/terms/s/stockoption.asp) to lay some foundation. \n",
    "\n",
    "----------------\n",
    "\n",
    "**Thailand Future Exchange(TFEX)** is a derivative market wich provides wide range of derivative such as \"Index Future\" and \"Index Options\". Each contracts expired at the end of each quarters and coded by the letter and numbers. Here is how to read the contract symbol:\n",
    "\n",
    " * S50H20 -> Means: this is an SET50 Index Future Expired at March 2020.\n",
    " \n",
    " * S50M20C900 -> Means: this is an SET50 Index Options at Strike Price 900 Expired at June 2020.\n",
    " \n",
    " The month code are as follows:\n",
    " \n",
    " * H -> March Expiration\n",
    " * M -> June Expiration\n",
    " * U -> September Expiration\n",
    " * Z -> December Expiration\n",
    " \n",
    " Thus **S50U22** is an **SET50 Index Future Contract expired at September 2022.**\n",
    " \n",
    " \n",
    " For more detailed explanation, please visit the [exchange](https://www.tfex.co.th/tfex/index.html?locale=en_US) tutorial.\n",
    "\n",
    "-----------------------\n",
    "\n",
    "Thanak Rattanopastkul, 2022 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset's Note\n",
    "\n",
    "There are 2 datasets in this notebook.\n",
    "* Merged-Table 1.csv\n",
    "* option_premium.csv\n",
    "\n",
    "### Merged-Table 1.csv\n",
    "This dataset is a historical price of SET50 Futures, an equity index future of Thailand's Stock Exchange. I Collected directly from the **TFEX**(Thailand's Future Exchange) [website](https://www.tfex.co.th/tfex/dailyMarketReport.html?locale=en_US) and merge all the series together and add a trading SYMBOL to every observations.\n",
    "    \n",
    "The collumns in Merged-Table 1.csv are as follows:\n",
    "* **Date** -> Trading day\n",
    "* **Open** -> Opening price\n",
    "* **High** -> Higest price duing the day\n",
    "* **Low** -> Lowest price duing the day\n",
    "* **Close** -> Closing price\n",
    "* **SP** -> [Settlement price](https://www.investopedia.com/terms/s/settlementprice.asp)\n",
    "* **Chg** -> Price change from last trading day\n",
    "* **%Chg** -> Price percent change from last trading day\n",
    "* **Vol** -> Trading volume\n",
    "* **OI** -> [Open Interest](https://www.investopedia.com/terms/o/openinterest.asp)\n",
    "* **Series** -> Trading symbol\n",
    "\n",
    "### option_premiun.csv\n",
    "This is a dataset manually collected by myself at the end of each trading day to record the price movement and any market beheaviors. I take only the relevant features and exported the dataset to CSV file.\n",
    "\n",
    "The collumns in Merged-Table 1.csv are as follows:\n",
    "* **Date** -> Trading day\n",
    "* **Series Name** -> Trading Symbol\n",
    "* **Underlying Close** -> Nearest SET50 Future Contract closing price \n",
    "* **Expiration** -> Options Expiration Date\n",
    "* **Day to expire** -> Day count to expiration\n",
    "* **Underlying Change** -> Nearest SET50 Future Contract price change from last observation\n",
    "* **ATM premium** -> SUM of Put and Call Options Premium at the [ATM](https://www.investopedia.com/terms/a/atthemoney.asp)\n",
    "* **+/-1 OTM premium** -> SUM of Put and Call Options Premium at the [+1 Call and -1 Put](https://www.investopedia.com/terms/o/outofthemoney.asp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "\n",
    "import os\n",
    "import gc\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/noonpritsana/Desktop/Nak/options_project/options_analysis/Merged-Table 1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [31]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m path_1 \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetcwd()\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Merged-Table 1.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m merged_future \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                  \u001b[49m\u001b[43minfer_datetime_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mdayfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m path_2 \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetcwd()\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/option_premium.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     10\u001b[0m manual_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(path_2, \n\u001b[1;32m     11\u001b[0m                   parse_dates\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpiration\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     12\u001b[0m                   infer_datetime_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     13\u001b[0m                   dayfirst\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     14\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py:610\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    605\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    606\u001b[0m     dialect, delimiter, delim_whitespace, engine, sep, defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m    607\u001b[0m )\n\u001b[1;32m    608\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 610\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py:462\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    459\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    461\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 462\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    465\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py:819\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwds:\n\u001b[1;32m    817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 819\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py:1050\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1046\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1047\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown engine: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mengine\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (valid options are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmapping\u001b[38;5;241m.\u001b[39mkeys()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1048\u001b[0m     )\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;66;03m# error: Too many arguments for \"ParserBase\"\u001b[39;00m\n\u001b[0;32m-> 1050\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py:1867\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1864\u001b[0m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musecols\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39musecols\n\u001b[1;32m   1866\u001b[0m \u001b[38;5;66;03m# open handles\u001b[39;00m\n\u001b[0;32m-> 1867\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open_handles\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1868\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py:1362\u001b[0m, in \u001b[0;36mParserBase._open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1358\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_handles\u001b[39m(\u001b[38;5;28mself\u001b[39m, src: FilePathOrBuffer, kwds: Dict[\u001b[38;5;28mstr\u001b[39m, Any]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1359\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1360\u001b[0m \u001b[38;5;124;03m    Let the readers open IOHanldes after they are done with their potential raises.\u001b[39;00m\n\u001b[1;32m   1361\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1362\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1363\u001b[0m \u001b[43m        \u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1364\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1365\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1366\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1367\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1368\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1369\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/common.py:642\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    640\u001b[0m         errors \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    641\u001b[0m     \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 642\u001b[0m     handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    643\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    644\u001b[0m \u001b[43m        \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    645\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    646\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    650\u001b[0m     \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    651\u001b[0m     handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/noonpritsana/Desktop/Nak/options_project/options_analysis/Merged-Table 1.csv'"
     ]
    }
   ],
   "source": [
    "path_1 = os.getcwd()+'/Merged-Table 1.csv'\n",
    "merged_future = pd.read_csv(path_1, \n",
    "                  parse_dates=['Date'],\n",
    "                  infer_datetime_format=True,\n",
    "                  dayfirst=True,\n",
    ")\n",
    "\n",
    "path_2 = os.getcwd()+'/option_premium.csv'\n",
    "\n",
    "manual_data = pd.read_csv(path_2, \n",
    "                  parse_dates=['date','Expiration'],\n",
    "                  infer_datetime_format=True,\n",
    "                  dayfirst=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_future.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_future.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many fof the merge_future data are in from of stings. Need to change it in to float and int.\n",
    "\n",
    "Eyeballing the CSV, there are some value in **Chg** and **%Chg** are \"-\" let's see if they can be recalculated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dashed_index =  merged_future.loc[(merged_future['Chg'] == '-') | (merged_future['%Chg']=='-')].index\n",
    "\n",
    "for i in dashed_index:\n",
    "    display(merged_future.loc[i-1:i+1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like the recalculation is possible. Let's change the dtype to string and calculate the Chg and %Chg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in merged_future.index:\n",
    "    \n",
    "        if merged_future.loc[i, 'Chg'] != '-':\n",
    "            for col in ['Open', 'High', 'Low', 'Close', 'SP', 'Chg','%Chg','Vol','OI']:\n",
    "                merged_future.loc[i, col] = float(merged_future.loc[i, col].replace('\"','').replace(',',''))\n",
    "        else:\n",
    "            col2 = ['Open', 'High', 'Low', 'Close', 'SP','Vol','OI']\n",
    "            for col2 in col2:   \n",
    "                merged_future.loc[i, col2] = float(merged_future.loc[i, col2].replace('\"','').replace(',',''))\n",
    "\n",
    "            merged_future.loc[i, 'Chg'] = float(9.9) #temp\n",
    "            merged_future.loc[i, '%Chg'] = float(9.9) #temp\n",
    "            merged_future.loc[i, 'Chg'] = merged_future.loc[i, 'SP'] - merged_future.loc[i-1, 'SP']\n",
    "            merged_future.loc[i, '%Chg'] = (merged_future.loc[i, 'SP'] - merged_future.loc[i-1, 'SP'])/merged_future.loc[i-1, 'SP']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if all the data are of dtype strings and no \"-\" on **Chg** and **%Chg**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_future.loc[dashed_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"merged_future\" contains 722 observations from SET50 Index Future from 2019 to 2022.\n",
    "\"manual_data\" contains 595 observations from SET0 Index Future and Options from 2019 to 2021.\n",
    "\n",
    "Since \"merged_future\" contains better Future Contracts trading data, The plan is to validate the data and merge two tables into one using Future data from \"merged_future\" and Options data from \"manual_data\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check and Validate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_future.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only some data from the manually collected data are missing. For the missing \"Underlying Close\" and \"Underlying Change\" , we can replace with the \"Close\" and \"Chg\" from the other dataset.\n",
    "\n",
    "Let's see the missing \"ATM premium\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_data.loc[manual_data['ATM premium'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the entries at \n",
    "\n",
    "* 2020-03-09 \n",
    "* 2020-03-12\n",
    "* 2020-03-23 \n",
    "\n",
    "those are very special case when COVID-19 crash the global market. The market actually crash and [Circuit Breaker](https://www.investopedia.com/terms/c/circuitbreaker.asp) was implimented on those three days. The Options market maker stop providing liquidity. Thus, those three very rare occasions should be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Entry Duplications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_data.loc[manual_data.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_future.loc[merged_future.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Data\n",
    "\n",
    "Will use date and Series as merging keys and extract only the needed columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_future_options = pd.merge(left=manual_data,right=merged_future,left_on=['date','Series Name'],right_on=['Date','Series'])\n",
    "merged_future_options.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list(merged_future.columns) #all columns taken \n",
    "a.extend(['Expiration','Day to expire','ATM premium','+/-1 OTM premium']) #extend with only needed column from another dataset.\n",
    "ready_df = merged_future_options[a]\n",
    "\n",
    "# delete the unused variable\n",
    "del [path_1,path_2,merged_future,manual_data,merged_future_options,dashed_index,col,col2]\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ready_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA\n",
    "\n",
    "Let's put all the most important features together to see the pattern. \n",
    "* Underlying Price (Close)\n",
    "* Trading Volume\n",
    "* Open Interest\n",
    "* Options price for both ATM an OTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval = [i*25 for i in range(26,48)] #to vertically frame between 650 - 1248 and use as yticks\n",
    "\n",
    "fig = plt.subplots(figsize=(15,15))\n",
    "plt.subplot(311)\n",
    "for symbol in ready_df['Series'].unique():\n",
    "    plt.plot(ready_df.loc[ready_df['Series'] == symbol, 'Date'],\n",
    "                    ready_df.loc[ready_df['Series'] == symbol, 'Close'],label=symbol)\n",
    "plt.title('SET50 Future Close Price')\n",
    "plt.grid()\n",
    "plt.yticks(interval)\n",
    "plt.vlines(['2020-03-09','2020-03-12','2020-03-23'],ymin=600,ymax=1200,label='Circuit Break',linestyles='dashed',colors='orange')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(312)\n",
    "plt.title('SET50 Future Trading Volume and Open Interest')\n",
    "for symbol in ready_df['Series'].unique():\n",
    "    plt.plot(ready_df.loc[ready_df['Series'] == symbol, 'Date'],\n",
    "                    ready_df.loc[ready_df['Series'] == symbol, 'OI'],label=symbol+' OI')\n",
    "plt.plot(ready_df.Date,ready_df.Vol,label='Volume')\n",
    "plt.vlines(['2020-03-09','2020-03-12','2020-03-23'],ymin=20000,ymax=680000,label='Circuit Break',linestyles='dashed',colors='orange')\n",
    "plt.grid()\n",
    "\n",
    "\n",
    "plt.subplot(313)\n",
    "plt.title('SET50 Options Price ATM total and OTM total')\n",
    "for symbol in ready_df['Series'].unique():\n",
    "    plt.plot(ready_df.loc[ready_df['Series'] == symbol, 'Date'],\n",
    "                    ready_df.loc[ready_df['Series'] == symbol, 'ATM premium'],c='r',label='ATM premiun')\n",
    "for symbol in ready_df['Series'].unique():\n",
    "    plt.plot(ready_df.loc[ready_df['Series'] == symbol, 'Date'],\n",
    "                    ready_df.loc[ready_df['Series'] == symbol, '+/-1 OTM premium'],c='0.5',label='OTM premium')\n",
    "plt.vlines(['2020-03-09','2020-03-12','2020-03-23'],ymin=0,ymax=200,label='Circuit Break',linestyles='dashed',colors='orange')\n",
    "plt.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the price distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval = [i*25 for i in range(24,46)]\n",
    "\n",
    "fig = plt.subplots(figsize=(7,4))\n",
    "plt.grid(axis='y')\n",
    "plt.title('SET50 Future Close Distribution')\n",
    "plt.hist(ready_df['Close'],bins=interval,orientation='vertical',linewidth=0.5,edgecolor='white')\n",
    "plt.xticks(interval,rotation=90)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During Q3 2019 to Q3 2021, Price clustered around 900-975 and 1050-1100. However the left skew is due to the COVID market Crash. At the Crash, the lowest Close was around 675."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What do we see form the EDA\n",
    "\n",
    "The data are from mid Q3 2019 to Q3 2021. Represented by 9 series of contracts duing those 9 quarters. The SET50 price stay around 900-975 the most. This could be a concept to build a range bound trading strategy on.\n",
    "\n",
    "**Other Remarkable Characteristics**\n",
    "\n",
    "**1. The Covid Plunge**\n",
    "\n",
    "There are a lot to take in from the above chart. First of all, the most eye-catching area is around March and April 2020 where there was a very steep drop in SET50 Future price from 1075 to 675 (around 37% loss) and the three vertical lines indicate the circuit breaker. That rare and unexpected event could be called a \"Black Swan\". We do not see that every day. However, after the plunge, the index seems to keep climbing up.\n",
    "\n",
    "**2. Volume Spike**\n",
    "\n",
    "It is expected that, the trading volume would peak during a panic sales. It did, from around 150k before the plunge, it peaked at over 600k at the Circuit Break.\n",
    "\n",
    "**3. Future Contract Rollover**\n",
    "\n",
    "At the expiration each quarter, all the future contract will be expired by settelement. This cause the OI of each future contract to go to zero and the next series gaining more OI.\n",
    "\n",
    "**4. Options Premium**\n",
    "\n",
    "The red lines are showing ATM while the grey lines are showing +/-1 OTM. All options price goes to zero at the expiration each quarter. However, whenever the SET50 Future Price rally, the Options price goes up too.\n",
    "\n",
    "Option price is the reason for this analysis. Eventhough the most influential model to price derivatives are [Black-Schole-Merton](https://www.investopedia.com/terms/b/blackscholes.asp) I still find it too complicated to use in the real-time Options trading on my daily basis.\n",
    "\n",
    "Therefore, this notebook is an attempt to create some personal and practical guideline for SET50 Options pricing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "\n",
    "Options price affected the most by time to expiration and underlying volatility. Let's calculate the change in Options price and underlying \"ATR\" (Average True Range) to represent volatility.\n",
    "\n",
    "Here is  the ATR formula:\n",
    "$$\n",
    "TR = max[(H-L) , abs(H-Cp) , abs(L-Cp)]\n",
    "$$\n",
    "$$\n",
    "ATR = (\\frac {1}{n}) \\sum_{i=1}^{n}TR_{i}\n",
    "$$\n",
    "\n",
    "ATR is basically a rolling average of price range from last n days. The more volatile market, the wider range between the Highest and Lowest price, and reflect to the bigger ATR number. The universal default of the n in ATR is 14.\n",
    "****\n",
    "Further explanation of [ATR](https://www.investopedia.com/terms/a/atr.asp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define ATR function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_tr(h,l,c):\n",
    "    tr = max([h-l,abs(h-c),abs(l-c)])\n",
    "    return tr\n",
    "\n",
    "def df_atr(df,h_col,l_col,c_col,n=14):\n",
    "    df['atr'] = None\n",
    "    for i in df.index:\n",
    "        df.loc[i, 'tr'] = cal_tr(h=df.loc[i, h_col],\n",
    "                                    l=df.loc[i, l_col],\n",
    "                                    c=df.loc[i, c_col])\n",
    "        df['atr'] = df['tr'].rolling(n).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_atr(ready_df,'High','Low','Close',14)\n",
    "ready_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ATR is done. \n",
    "\n",
    "Since ATM Options premium has two part. Intrinsic Value and Time Value. Another crucial information is Time Value for ATM options since this is the main profit for Options traders. Time value in a word is an Options premium that exceed the diffecence between the Strikeprice and the Underlying price. For more infomation about Time Value please follow this [link](https://www.investopedia.com/terms/t/timevalue.asp)\n",
    "\n",
    "### Calculate ATM Time Value\n",
    "\n",
    "Since the Strikeprice are thos multiples of 25, Therefore, at any underlying price : \n",
    "$$\n",
    "TV = ATM.Premium - (Nearest.Strike - Close)\n",
    "$$\n",
    "\n",
    "For example at index 523 above: \n",
    "* Close = 968.6\n",
    "* Nearest Strike = 975\n",
    "* ATM = 8.5\n",
    "\n",
    "$$\n",
    "TV = 8.5-(975-968.6) = 2.1\n",
    "$$\n",
    "\n",
    "Noted that this is at 1 day before expiration, so the premium is very low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ready_df.index:\n",
    "    ready_df.loc[i, 'atm_tv'] = ready_df.loc[i, 'ATM premium']-abs((25*round(ready_df.loc[i, 'Close']/25))-ready_df.loc[i, 'Close']) #25*round(ready_df.loc[i, 'Close']/25) is to round to the nearest strike\n",
    "\n",
    "ready_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of curiosity, let's see ATM OTM and TV together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,7))\n",
    "plt.title('SET50 Options Price ATM total, OTM total and Time Value')\n",
    "for symbol in ready_df['Series'].unique():\n",
    "    plt.plot(ready_df.loc[ready_df['Series'] == symbol, 'Date'],\n",
    "                    ready_df.loc[ready_df['Series'] == symbol, 'ATM premium'],c='r',label='ATM premiun')\n",
    "for symbol in ready_df['Series'].unique():\n",
    "    plt.plot(ready_df.loc[ready_df['Series'] == symbol, 'Date'],\n",
    "                    ready_df.loc[ready_df['Series'] == symbol, 'atm_tv'],c='g',label='TV')\n",
    "for symbol in ready_df['Series'].unique():\n",
    "    plt.plot(ready_df.loc[ready_df['Series'] == symbol, 'Date'],\n",
    "                    ready_df.loc[ready_df['Series'] == symbol, '+/-1 OTM premium'],c='0.5',label='OTM premium')\n",
    "plt.vlines(['2020-03-09','2020-03-12','2020-03-23'],ymin=0,ymax=200,label='Circuit Break',linestyles='dashed',colors='orange')\n",
    "plt.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TV is a lot more volatile compared to ATM. From now on, this notebook will be focusing only on Time Value as an Option Price. The +/-1 OTM Premium is already time value without any intrinsic value.\n",
    "\n",
    "Next let's cast the \"Days to expire\" column from str to int for later use in analytics.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ready_df.index:    \n",
    "    ready_df.loc[i, 'dte'] = int(ready_df.loc[i, 'Day to expire'].replace(\"'\",'').replace('d','').replace('ms',''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's create another column day from the quarter start (dfqs). This information will be use to compare across series for Options pice at the same interval comparaed to the start of the quarter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference: a snippet from Alaxander at https://stackoverflow.com/questions/46167550/day-number-of-a-quarter-for-a-given-date-in-pandas\n",
    "\n",
    "ready_df['q_day'] = [int((date - quarter_period.start_time).days + 1) for date, quarter_period in zip(ready_df['Date'], pd.PeriodIndex(ready_df['Date'], freq='Q'))]\n",
    "\n",
    "# note for later code reading\n",
    "# quarter_period is an insntance of a querter at a given time\n",
    "# quarter_period.start_time returns the first day of that period.\n",
    "# Thus ready_df['Date']-quarter_perid.startime+1 returns a date count of a given day from it's quarter beginning. +1 is to offset the first_day - first_day = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA Continued\n",
    "\n",
    "Since we have some new features from the engineering, let's explore them beginning with the relationship between TV and ATR at each day to expiration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop first 13 lines with missing ATR \n",
    "ready_df.dropna(inplace=True)\n",
    "ready_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18,7))\n",
    "\n",
    "ax1 = plt.subplot(121)\n",
    "for sym in ready_df['Series'].unique():\n",
    "    plt.plot(ready_df.loc[ready_df['Series']==sym, 'q_day'], ready_df.loc[ready_df['Series']==sym , 'atm_tv'].rolling(5).mean(), label=sym,linewidth=1)\n",
    "plt.title('ATM TV at different day from quarter begins')\n",
    "plt.xticks(np.linspace(0,90,10))\n",
    "plt.xlabel('Quarter Day')\n",
    "plt.ylabel('Time Value at ATM')\n",
    "plt.vlines(x=[30,60,90],ymin=0,ymax=150,linestyles='dashed')\n",
    "\n",
    "ax2 = plt.subplot(122)\n",
    "for sym in ready_df['Series'].unique():\n",
    "    plt.plot(ready_df.loc[ready_df['Series']==sym, 'q_day'], ready_df.loc[ready_df['Series']==sym , '+/-1 OTM premium'].rolling(5).mean(), label=sym,linewidth=1)\n",
    "plt.title('+/-1 OTM Premium at different day from quarter begins')\n",
    "plt.xticks(np.linspace(0,90,10))\n",
    "plt.xlabel('Quarter Day')\n",
    "plt.ylabel('Time Value at +/-1 OTM')\n",
    "plt.vlines(x=[30,60,90],ymin=0,ymax=150,linestyles='dashed')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout(pad=2)\n",
    "plt.show()    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the premiums declines to zero over the period of quarter. On special occastion of COVID-19 at the last month of H20 (March 2020) the premium jumped fom around 20 to almost 80 at as the contract is just around 10 days to the expiration.\n",
    "\n",
    "This effect continue on to M20 and U20. We saw ATM premium around 140 and 90 respectively at the beginning of the quarter instead of aroud 45.\n",
    "\n",
    "\n",
    "The chart axes show only premium and day to expiration. Let's try 3D plot a bit.\n",
    "\n",
    "### ciurrent working line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget \n",
    "# use this widget for interactive 3d plot\n",
    "from mpl_toolkits.mplot3d import Axes3D # use this module for interactive 3d plot\n",
    "\n",
    "sym = 'M20'\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')# GCA = get current axes : this line is for static plot\n",
    "#ax = Axes3D(fig) # use this ax for interactive 3d plot\n",
    "ax.plot_trisurf(ready_df.loc[ready_df['Series']==sym, 'atr'],ready_df.loc[ready_df['Series']==sym, 'dte'],ready_df.loc[ready_df['Series']==sym, 'atm_tv'],\n",
    "                        cmap=plt.cm.jet,edgecolor='black',linewidth=0.5)\n",
    "ax.set_title('{} ATM Time Value by 1D ATR14 and Day to expiration'.format(sym))\n",
    "ax.set_xlabel('Daily ATR 14')\n",
    "ax.set_ylabel('DTE')\n",
    "ax.set_zlabel('TV at ATM')\n",
    "plt. tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Current Working Cell\n",
    "\n",
    "## Multi Series Static 3d Subplots and followed by a interactive 3d plot.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self Note \n",
    "- Linear Regression To ATM OTM pricing using ATR / Day to expire /etc. as features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the processed CSV\n",
    "# ready_df.to_csv('ready_df.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
